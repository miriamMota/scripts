---
title: "Analisis TFM"
author: "Miriam Mota"
date: "November 30, 2017"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r paquetes}
# require(devtools)
# install_github("uebvhir/installifnot")
require(installifnot)
installifnot("oro.nifti")
installifnot("compareGroups")

installGitifnot("miriammota","mmotaF",force.install = F)

if (!require(devtools)) {install.packages('devtools')}
# devtools::install_github("muschellij2/fslr", force = T ) 

# devtools::install_github("stnava/cmaker")
require(cmaker)
# devtools::install_github("stnava/ITKR")
require(ITKR)
# devtools::install_github("stnava/ANTsR")
require(ANTsR)
# devtools::install_github("muschellij2/extrantsr")
library(extrantsr)

Sys.getenv("FSLDIR")
library(fslr)
have.fsl() 
```


# Lectura y visualización de resonancia magnetica

```{r}
nifti_files_ALL <- grep(".nii.gz",list.files("dades/orig/", recursive = T), value = T)
nifti_files <- nifti_files_ALL[!nifti_files_ALL %in% grep("-FU",nifti_files_ALL, value = T) ]

if (!file.exists("dades/orig/dat_nifti.Rda")) {
  dat_nifti <- list()
  ptm <- proc.time()
  for (i in seq_along(nifti_files)) {
    name_nifti <- paste0(unlist(strsplit(nifti_files[i], "/"))[1:2], collapse = "_")
    dat_nifti[[name_nifti]] <- readNIfTI(paste0("dades/orig/",nifti_files[i]),reorient = FALSE)
  }
  # proc.time() - ptm
  save(dat_nifti, file = "dades/orig/dat_nifti.Rda")
} else{
  load("dades/orig/dat_nifti.Rda")
}

dat_clin <- read.table("dades/orig/participants.tsv", header = T, dec = ".", sep = "\t")
dat_clin <- re_name(dat_clin)


# plantillaGeneralNorm <- readNIfTI("Neurohacking/Neurohacking_data-master/Template/MNI152_T1_1mm_brain.nii.gz",reorient = FALSE)

```

```{r}
dat_clin$age_at_onset_frequent_CB_use[dat_clin$age_at_onset_frequent_CB_use == "n/a"] <- NA
dat_clin$age_at_onset_frequent_CB_use <- as.numeric(as.character(dat_clin$age_at_onset_frequent_CB_use))
```


```{r}
res <- compareGroups(group ~. - participant_id , data = dat_clin)
restab <- createTable(res)
descPlot(dat_clin[,c("group",names(res))], y = "group")
```



<!-- % https://neuroconductor.org/neuroc-help-preprocess-mri-within -->
```{r}
### 4.4 
# registered_n4 = ants_regwrite(filename=dat_nifti,
# template.file = template, remove.warp = TRUE,
# typeofTransform = "Rigid") 

## VISUALIZACION

oro.nifti::slice(dat_nifti$`sub-101_ses-BL`, z = 125, plane = "axial")
image(dat_nifti$`sub-101_ses-BL`, useRaster = FALSE)
ortho2(robust_window(dat_nifti$`sub-101_ses-BL`))


## preprocessing

outfiles <- paste0("dades/processed/",gsub(".nii.gz", "_processed.nii.gz", sapply(strsplit(nifti_files, "/"),"[[", 4)))

if (!all(file.exists(outfiles))) { 
preprocess_mri_within(files = dat_nifti, 
                      retimg = F, 
                      outfiles = outfiles, 
                      correction = "N4",
                      correct = TRUE,
                      skull_strip = FALSE, 
                      typeofTransform = "SyN")
}

proc_imgs = lapply(outfiles, readnii) ## leemos datos procesados



lapply(proc_imgs, ortho2) ## mostramos datos procesados





outfile <- paste0("dades/SS/",gsub(".nii.gz", "_SS.nii.gz", strsplit(nifti_files[1], "/")[[1]][4]))
if (!file.exists(outfile)) {
  ss = extrantsr::fslbet_robust(dat_nifti[[1]], 
    remover = "double_remove_neck",
    outfile = outfile)
} else {
  ss = readnii(outfile)
}



mask = ss > 0
proc_imgs = lapply(proc_imgs, mask_img, mask = mask)
dd = dropEmptyImageDimensions(mask, other.imgs = proc_imgs)
mask = dd$outimg
proc_imgs = dd$other.imgs
lapply(proc_imgs, ortho2) ## mostramos imagenes

oro.nifti::slice(proc_imgs[[1]], z = 125, plane = "axial")
image(proc_imgs[[1]], useRaster = FALSE)
ortho2(robust_window(proc_imgs[[1]]))


# applying a brain mask to all registered images
brain = fslbet_robust(img = outfiles[1], correct = FALSE, verbose = FALSE)
mask = brain > 0
masked_imgs = lapply(outfiles, fslmask, mask = mask,verbose = FALSE)
orthographic(masked_imgs[[2]])





```


```{r}

n4_proc_imgs = plyr::llply(
  proc_imgs,
  bias_correct,
  correction = "N4",
  mask = mask,
  retimg = TRUE,
  .progress = "text")

outfiles = paste0("dades/proc_N4_SS/",gsub(".nii.gz", "_proc_N4_SS.nii.gz", sapply(strsplit(nifti_files, "/"),"[[", 4)))

if (!all(file.exists(outfiles))) {
  mapply(function(img, outfile) {writenii(img, filename = outfile)}, n4_proc_imgs, outfiles)
}

```




## Normalización

```{r}

df0 = sapply(proc_imgs, function(x){
  x[ mask == 1 ]
})
long0 = reshape2::melt(df0)
colnames(long0) = c("ind", "sequence", "value")
aa <- sapply(strsplit(names(dat_nifti), "-"),"[[", 2)
id_pac <- paste0(sapply(strsplit(aa, "_"),"[[", 1), dat_clin[order(dat_clin$participant_id), "group"])
long0$sequence <- as.factor(long0$sequence)
levels(long0$sequence) <- id_pac
long0$ind = NULL
df0 = data.frame(df0)


ggplot(long0, aes(x = value, colour = factor(sequence))) + 
  geom_line(stat = "density")

## Intensity Normalization
norm_imgs = plyr::llply(
  proc_imgs, 
  zscore_img,
  margin = NULL,
  centrality = "mean",
  variability = "sd",
  mask = mask,
  .progress = "text")

## Visualizing the marginal intensities
# Aquí podemos hacer un data.frame de las imágenes normalizadas. También creamos un data.frame largo (llamado long) para trazar en ggplot2
df = sapply(norm_imgs, function(x){
  x[ mask == 1 ]
})
long = reshape2::melt(df)
colnames(long) = c("ind", "sequence", "value")
long$sequence <- as.factor(long$sequence)
levels(long$sequence) <- id_pac
long$ind = NULL
df0 = data.frame(df0)
long$ind = NULL
df = data.frame(df)

# marginal distributions
# Aquí graficamos las distribuciones de cada secuencia de imágenes por separado.
ggplot(long, aes(x = value, colour = factor(sequence))) + 
  geom_line(stat = "density")


outfiles = paste0("dades/norm_imgs/",gsub(".nii.gz", "_norm_imgs.nii.gz", sapply(strsplit(nifti_files, "/"),"[[", 4)))

names(norm_imgs) <- paste0(names(dat_nifti), "_norm_imgs")

if (!all(file.exists(outfiles))) {
  mapply(function(img, outfile) {writenii(img, filename = outfile)}, norm_imgs, outfiles)
}


```


#Extracción GM WM

Bias Field Correction: La corrección del campo de polarización es la corrección de las variaciones del contraste de la imagen debido a la falta de homogeneidad del campo magnético [18]. El enfoque más comúnmente adoptado es la corrección de campo de polarización N4.


```{r}
## segmentation: separar el cervell en els diferents teixits, grey matter and white matter

require(fslr)

run <- FALSE
if (run) {
## conduct bias field correction
fast_img = lapply(norm_imgs, fslr::fsl_biascorrect)

save(fast_img, file = "dades/fast_img.Rda")

## perform brain extraction
bet = lapply(fast_img, fslr::fslbet)
save(bet, file = "dades/bet.Rda")
}else{
  load(file = "dades/fast_img.Rda")
  load(file = "dades/bet.Rda")
}

## perform segmentation
outfiles = paste0("dades/BET_FAST/",gsub(".nii.gz", "_BET_FAST.nii.gz", sapply(strsplit(nifti_files, "/"),"[[", 4)))
run <- segmentation <- FALSE
if (run) {
  fast <- list()
  for (i in seq_along(outfiles)) {
    fast[[i]] <- fast(bet[[i]], outfiles[i])
  }

  save(fast,file = "dades/BET_FAST/fast_segm.Rda")

}else{
  load("dades/BET_FAST/fast_segm.Rda")
}

## displays CSF segmentation
for (i in seq_along(bet)) {
ortho2(bet[[i]], fast[[i]] == 1, col.y = alpha("red",.5), text = nifti_files[i] )
}

## displays GM segmentation
for (i in seq_along(bet)) {
ortho2(bet[[i]], fast[[i]] == 2, col.y = alpha("red",.5), text = nifti_files[i] )
}

## displays WM segmentation
for (i in seq_along(bet)) {
ortho2(bet[[i]], fast[[i]] == 3, col.y = alpha("red",.5), text = nifti_files[i] )
}

## fast, 0 = background, 1 =GM, 2 = WM
## genera 4 fitxers nous:
# pve_0 CSF
# pve_1 GM
# pve_2 WM

## si "sumesim" tots la probablilita hauria de ser 1. 

## passem a llegir els nous fitxer generats.
pveCSF_files <- grep("pve_0", list.files("dades/BET_FAST/"), value = T)

if (!file.exists("dades/BET_FAST/dat_pveCSF.Rda")) {
  dat_pveCSF <- list()
  ptm <- proc.time()
  for (i in seq_along(pveCSF_files)) {
    name_nifti <- paste0(unlist(strsplit(pveCSF_files[i], "/"))[1:2], collapse = "_")
    dat_pveCSF[[name_nifti]] <- readNIfTI(paste0("dades/BET_FAST/",pveCSF_files[i]),reorient = FALSE)
  }
  save(dat_pveCSF, file = "dades/BET_FAST/dat_pveCSF.Rda")
}else{
  load("dades/BET_FAST/dat_pveCSF.Rda")
}



pveGM_files <- grep("pve_1", list.files("dades/BET_FAST/"), value = T)

if (!file.exists("dades/BET_FAST/dat_pveGM.Rda")) {
  dat_pveGM <- list()
  ptm <- proc.time()
  for (i in seq_along(pveGM_files)) {
    name_nifti <- paste0(unlist(strsplit(pveGM_files[i], "/"))[1:2], collapse = "_")
    dat_pveGM[[name_nifti]] <- readNIfTI(paste0("dades/BET_FAST/",pveGM_files[i]),reorient = FALSE)
  }
  save(dat_pveGM, file = "dades/BET_FAST/dat_pveGM.Rda")
}else{
  load("dades/BET_FAST/dat_pveGM.Rda")
}


pveWM_files <- grep("pve_2", list.files("dades/BET_FAST/"), value = T)

if (!file.exists("dades/BET_FAST/dat_pveWM.Rda")) {
  dat_pveWM <- list()
  ptm <- proc.time()
  for (i in seq_along(pveWM_files)) {
    name_nifti <- paste0(unlist(strsplit(pveWM_files[i], "/"))[1:2], collapse = "_")
    dat_pveWM[[name_nifti]] <- readNIfTI(paste0("dades/BET_FAST/",pveWM_files[i]),reorient = FALSE)
  }
  save(dat_pveWM, file = "dades/BET_FAST/dat_pveWM.Rda")
}else{
  load("dades/BET_FAST/dat_pveWM.Rda")
}


# df1 <- array2df(dat_pveGM[[1]])


require(MRIaggr)
if (!file.exists("dades/BET_FAST/dat_pveGM_arr.Rda")) {
  dat_pveGM_arr <- list()

  for (i in seq_along(pveGM_files)) {
    name_nifti <- paste0(unlist(strsplit(pveGM_files[i], "/"))[1:2], collapse = "_")
    dat_pveGM_arr[[name_nifti]] <- array2df(dat_pveGM[[i]])
  }
  save(dat_pveGM_arr, file = "dades/BET_FAST/dat_pveGM_arr.Rda")
}else{
  load("dades/BET_FAST/dat_pveGM_arr.Rda")
}


if (!file.exists("dades/BET_FAST/dat_pveGM_arr_del0.Rda")) {
  dat_pveGM_arr_del0 <- list()

  for (i in seq_along(pveGM_files)) {
    name_nifti <- paste0(unlist(strsplit(pveGM_files[i], "/"))[1:2], collapse = "_")
    dat_pveGM_arr_del0[[name_nifti]] <- dat_pveGM_arr[[i]][-which(dat_pveGM_arr[[i]]$res == 0), ]
  }
  save(dat_pveGM_arr_del0, file = "dades/BET_FAST/dat_pveGM_arr_del0.Rda")
}else{
  load("dades/BET_FAST/dat_pveGM_arr_del0.Rda")
}


require(plyr)
dat_GM_del0 <- ldply(dat_pveGM_arr_del0, data.frame)
save(dat_GM_del0, file = "dades/BET_FAST/dat_pveGM_del0_dataframe.Rda")
load(file = "dades/BET_FAST/dat_pveGM_del0_dataframe.Rda")


all.equal(dat_pveGM_arr_del0[[1]]$k,dat_pveGM_arr[[21]]$k)
# paste0("dat_pveGM_arr[[",1:42,"]]$res", collapse = ", ")
dat_GM_wide <- cbind(dat_pveGM_arr[[1]], dat_pveGM_arr[[2]]$res, dat_pveGM_arr[[3]]$res, dat_pveGM_arr[[4]]$res, dat_pveGM_arr[[5]]$res, dat_pveGM_arr[[6]]$res, dat_pveGM_arr[[7]]$res, dat_pveGM_arr[[8]]$res, dat_pveGM_arr[[9]]$res, dat_pveGM_arr[[10]]$res, dat_pveGM_arr[[11]]$res, dat_pveGM_arr[[12]]$res, dat_pveGM_arr[[13]]$res, dat_pveGM_arr[[14]]$res, dat_pveGM_arr[[15]]$res, dat_pveGM_arr[[16]]$res, dat_pveGM_arr[[17]]$res, dat_pveGM_arr[[18]]$res, dat_pveGM_arr[[19]]$res, dat_pveGM_arr[[20]]$res, dat_pveGM_arr[[21]]$res, dat_pveGM_arr[[22]]$res, dat_pveGM_arr[[23]]$res, dat_pveGM_arr[[24]]$res, dat_pveGM_arr[[25]]$res, dat_pveGM_arr[[26]]$res, dat_pveGM_arr[[27]]$res, dat_pveGM_arr[[28]]$res, dat_pveGM_arr[[29]]$res, dat_pveGM_arr[[30]]$res, dat_pveGM_arr[[31]]$res, dat_pveGM_arr[[32]]$res, dat_pveGM_arr[[33]]$res, dat_pveGM_arr[[34]]$res, dat_pveGM_arr[[35]]$res, dat_pveGM_arr[[36]]$res, dat_pveGM_arr[[37]]$res, dat_pveGM_arr[[38]]$res, dat_pveGM_arr[[39]]$res, dat_pveGM_arr[[40]]$res, dat_pveGM_arr[[41]]$res, dat_pveGM_arr[[42]]$res)

names(dat_GM_wide) <- c("i","j","k", sapply(strsplit(names(dat_pveGM_arr), "_"),"[[", 1))

row_sub <- apply(dat_GM_wide[,4:ncol(dat_GM_wide)], 1, function(x) all(x == 0))

dat_GM_wide_del0 <- dat_GM_wide[!row_sub,]
save(dat_GM_wide_del0, file = "dades/BET_FAST/dat_GM_wide_del0_dataframe.Rda")

## calculating CSF GM and WM volumes
# reads in the pve file for CSV
threshold = 0.33
aa <- sapply(strsplit(names(dat_pveGM), "_"),"[[", 1)
id_pac <- sapply(strsplit(aa, "-"),"[[", 2)

vol_pveGM <- NA
for (i in seq_along(dat_pveGM)) {
# calculate the product of voxel dimensions (volume)
vdim_GM = prod(voxdim(dat_pveGM[[i]]))

# reads in the pve file for WM
nvoxels_GM <- sum(dat_pveGM[[i]] > threshold)

# calculate the volume of GM in mL
vol_pveGM[i] <- vdim_GM*nvoxels_GM / 1000
}

```



<!-- ## Suavizado -->



<!-- ```{r} -->

<!-- ``` -->



```{r}

dat_vol <- data.frame(participant_id = id_pac, volume = vol_pveGM)

dat_vol_merge <- merge(dat_clin, dat_vol, by = "participant_id")
save(dat_vol_merge, file = "dades/dat_vol_merge.Rda")
require(caret)
t.test(dat_vol_merge$volume ~ dat_vol_merge$group, alternative = "less")
boxplot_bw(y = "volume", group = "group", dat = dat_vol_merge)
roc1 <- doROC(group ~ volume, dat = dat_vol_merge)
roc1$mod$y <- factor(roc1$mod$y, 0:1, levels(dat_vol_merge$group))
pred <- ifelse(predict(roc1$mod,type = "response") > roc1$thres.best, levels(dat_vol_merge$group)[2],levels(dat_vol_merge$group)[1])
(confMat <- confusionMatrix(pred, roc1$mod$y))
# pt <- aggregate(1/(1 + exp(-dat_vol_merge[names(pred),"volume"]))~ pred, FUN = "min" )[2,2]

```





# Algoritmos Deep Learning MRI

```{r}

bb <- sapply(strsplit(names(dat_GM_wide_del0[,4:ncol(dat_GM_wide)]), "_"),"[[", 1)
id_pac <- sapply(strsplit(bb, "-"),"[[", 2)

if (all.equal(dat_vol_merge$participant_id, as.numeric(id_pac)) ) yy <- dat_vol_merge$group

# install.packages("deepnet")
# require(deepnet)
# nn.train(x = as.matrix(dat_GM_wide_del0[,4:ncol(dat_GM_wide)]), y = as.numeric(yy) , initW=NULL, initB=NULL, hidden=c(50,20), activationfun="sigm", learningrate=0.8, momentum=0.5, learningrate_scale=1, output="sigm", numepochs=3, batchsize=100, hidden_dropout=0, visible_dropout=0)

```

```{r}
require(mmotaF)
dat_clin <- read.table("dades/orig/participants.tsv", header = T, dec = ".", sep = "\t")
dat_clin <- re_name(dat_clin)

load("dades/BET_FAST/dat_GM_wide_del0_dataframe.Rda")
dat_GM_wide_del0 <- dat_GM_wide_del0[,-c(1:3)]
dat_GM_wide_del0_t <- as.data.frame(t(dat_GM_wide_del0))


all.equal(as.numeric(sapply(strsplit(rownames(dat_GM_wide_del0_t), "-"),"[[", 2)), 
          sort(as.numeric(sapply(strsplit(rownames(dat_GM_wide_del0_t), "-"),"[[", 2))))

all.equal(as.numeric(sapply(strsplit(rownames(dat_GM_wide_del0_t), "-"),"[[", 2)), 
          dat_clin[order(dat_clin$participant_id), "participant_id"])

dat_GM_wide_del0_t$group <- dat_clin[order(dat_clin$participant_id), "group"]
dat_GM_wide_del0_t[["group"]] <- dat_clin[order(dat_clin$participant_id), "group"]

require(caret)
ctrl <- trainControl(method = "cv", number = 3)
gridx <- expand.grid(size = 3, decay = 0.125)
nnet_fit <- train(group ~ . , data = dat_GM_wide_del0_t[, 2471258:2472368], 
                  method = "nnet", 
                  trControl = ctrl, 
                  tuneGrid = gridx)
test_pred <- predict(nnet_fit, newdata =  dat_GM_wide_del0_t[, 2472158:2472367])
(c_nnet <- confusionMatrix(test_pred, dat_GM_wide_del0_t$group ))


set.seed(12345) 
train <- sample(1:nrow(dat_GM_wide_del0_t),round(2*nrow(dat_GM_wide_del0_t)/3,0))
# train y test datos 
dat_norm_train <- dat_GM_wide_del0_t[train,]
dat_norm_test <- dat_GM_wide_del0_t[-train,]

knn_pred <- class::knn(train = dat_norm_train[, 1:2472367], 
                       test = dat_norm_test[, 1:2472367], 
                       cl = dat_norm_train$group, k = 1 )

(c_knn <- confusionMatrix(table(knn_pred, dat_norm_test$group)))


knn_pred <- plot(class::knn(train = dat_norm_train[, 1:2472367], 
                       test = dat_norm_test[, 1:2472367], 
                       cl = dat_norm_train$group, k = 5 ))

(c_knn <- confusionMatrix(table(knn_pred, dat_norm_test$group)))


require(e1071)
naiveB <- naiveBayes(group ~ .  , data = dat_norm_train)
save(naiveB, file = "naiveB.Rda")


svm_lin <- svm(x = dat_norm_train[, 1:2472367], y = dat_norm_train$group, kernel = "linear") 
pl_lin <- predict(svm_lin, dat_norm_test[, 1:2472367])
pl_lin_res <- confusionMatrix(table(pl_lin, dat_norm_test$group))
save(pl_lin_res, file = "results/svm_lin.Rda")

svm_rbf <- svm(x = dat_norm_train[, 1:2472367], y = dat_norm_train$group) 
pl_rbf <- predict(svm_rbf, dat_norm_test[, 1:2472367])
pl_rbf_res <- confusionMatrix(table(pl_rbf, dat_norm_test$group))
 save(svm_rbf, file = "svm_rbf.Rda")

svm_pm <- svm(x = dat_norm_train[, 1:2472367], y = dat_norm_train$group, kernel = "polynomial") 
pl_pm <- predict(svm_pm, dat_norm_test[, 1:2472367])
pl_pm_res <- confusionMatrix(table(pl_pm, dat_norm_test$group))
save(pl_pm_res, file = "results/svm_pm.Rda")


svm_sm <- svm(x = dat_norm_train[, 1:2472367], y = dat_norm_train$group, kernel = "sigmoid") 
pl_sm <- predict(svm_sm, dat_norm_test[, 1:2472367])
pl_sm_res <- confusionMatrix(table(pl_sm, dat_norm_test$group))
save(pl_sm_res, file = "results/svm_sm.Rda")

 
 
```
